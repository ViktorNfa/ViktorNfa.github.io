

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Scalable MARL for collision avoidance - Andreu Matoses Gimenez</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Andreu Matoses Gimenez">
<meta property="og:title" content="Scalable MARL for collision avoidance">


  <link rel="canonical" href="http://localhost:4000/projects/2-MSc_thesis_MARL">
  <meta property="og:url" content="http://localhost:4000/projects/2-MSc_thesis_MARL">



  <meta property="og:description" content="Scalable multi-agent reinforcement learning for formation control with collision avoidance. This work was my Master’s Thesis while at KTH Royal Institute of Technology.">





  

  












  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Andreu Matoses Gimenez",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Andreu Matoses Gimenez Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:4000/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:4000/images/icons/favicon-16x16.png">
<link rel="manifest" href="http://localhost:4000/images/icons/site.webmanifest">
<link rel="shortcut icon" href="http://localhost:4000/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#2b5797">
<meta name="msapplication-config" content="http://localhost:4000/images/icons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Andreu Matoses Gimenez</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/projects/">Research</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/teaching/">Teaching</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">Résumé</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/contact/">Contact</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/profile.jpg" class="author__avatar" alt="Andreu Matoses Gimenez">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Andreu Matoses Gimenez</h3>
    <p class="author__bio">PhD in Robotics and Control, <b>T</b><span style='color: #80c9e4; font-weight: bold;'>U</span> Delft </p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Contact</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Delft, Netherlands</li>
      
      
      
      
        <li><a href="mailto:A.MatosesGimenez[at]tudelft.nl"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email ([at] = @)</a></li>
        <!-- <li><i class="fas fa-fw fa-envelope" aria-hidden="true"></i>  A.MatosesGimenez[at]tudelft.nl</li> -->
      
      
       
      
      
      
      
        <li><a href="https://www.linkedin.com/in/andreu-matoses"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
      
        <li><a href="https://github.com/AndreuMatoses"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=mQvQ-DYAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Scalable MARL for collision avoidance">
    <meta itemprop="description" content="Scalable multi-agent reinforcement learning for formation control with collision avoidance. This work was my Master’s Thesis while at KTH Royal Institute of Technology.">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Scalable MARL for collision avoidance
</h1>
          
        
        
        
        
        
        </header>
      

      <section class="page__content" itemprop="text">
        <p>The code generated to implement the scalable MARL algorithm can be found in this <a href="https://github.com/AndreuMatoses/scalable-collision-avoidance-RL">repository</a>.</p>

<figure class="half ">
  
    
      <img src="http://localhost:4000/images/msc_thesis/n10_good.gif" alt="10 agents moving" />
    
  
    
      <img src="https://user-images.githubusercontent.com/46297629/216676961-4b61d1f0-9b1e-4ca9-ad81-2c36c6a77886.gif" alt="5 agents moving" />
    
  
  
    <figcaption>Five agents with limited sensing range moving towards formation while avoiding collisions
</figcaption>
  
</figure>

<p>This work is part of my Mater’s Thesis at the Royal Institute of Technology (KTH), Stockholm, Sweden (URL available soon). The scalable part of this work is inspired by the paper <a href="https://arxiv.org/abs/1912.02906">Scalable Reinforcement Learning for Multi-Agent Networked Systems</a>. The approach presented on the thesis exploits the structure of the designed reward to present \(\Delta\)-disk local approximation of the individual Q functions and policy gradients.</p>

<h2 id="important-scripts">Important Scripts</h2>

<ul>
  <li><a href="https://github.com/AndreuMatoses/scalable-collision-avoidance-RL/blob/main/drone_env.py">drone_env.py</a>: Script containing the environment class and its methods. The main methods follow the structure of the OpenGym RL environments, such as <code class="language-plaintext highlighter-rouge">.step()</code> and <code class="language-plaintext highlighter-rouge">.reset()</code>.</li>
  <li><a href="https://github.com/AndreuMatoses/scalable-collision-avoidance-RL/blob/main/train_problem.py">train_problem.py</a>: Script containing the training of the main problem.</li>
  <li><a href="https://github.com/AndreuMatoses/scalable-collision-avoidance-RL/blob/main/SAC_agents.py">SAC_agents.py</a>: Script containing the agent classes and its policy classes</li>
  <li><a href="https://github.com/AndreuMatoses/scalable-collision-avoidance-RL/blob/main/benchmark_agent.py">benchmark_agent.py</a>: Scripts to run trained agents and benchmark their performance</li>
</ul>

<h2 id="training-of-the-scalable-agents">Training of the scalable agents</h2>

<p>The schema of the algorithm used is presented below. The scalable actor-critic agents are trained for each robotic agent. There are a total of <em>n</em> agents.</p>

<p><img src="https://user-images.githubusercontent.com/46297629/216669445-a07214a4-08e5-46d8-85e5-f30855f3e8fc.png" alt="image" width="600" class="align-center" /></p>

<h2 id="structure-of-the-training-script">Structure of the training script</h2>

<p><img src="https://user-images.githubusercontent.com/46297629/216669814-5e9465ef-f0a8-46cb-a53a-35645a799e70.png" alt="image" width="600" class="align-center" /></p>

<h2 id="relevant-results">Relevant results</h2>

<h3 id="softmax-discrete-policy">Softmax discrete policy</h3>

<p>The individual policy for each agent is of the shape:</p>

<p><img src="https://user-images.githubusercontent.com/46297629/216673328-1cea1dc8-26fe-4b50-9618-ccf30043801e.png" alt="image" /></p>

<p>Some examples of trajectories obtained after successful training are as follow</p>

<p><img src="https://user-images.githubusercontent.com/46297629/216674048-68c2473c-b398-4d60-8bfc-de6049065911.png" alt="image" /></p>

<h3 id="continous-normally-distributed-policy">Continous normally distributed policy</h3>

<p>The individual policy for each agent is of the shape:</p>

<p><img src="https://user-images.githubusercontent.com/46297629/216673469-c5b07220-ee01-4d7f-a1bf-010b21619b19.png" alt="image" /></p>

<p>Some examples of trajectories obtained after successful training are as follow</p>

<p><img src="https://user-images.githubusercontent.com/46297629/216673912-91e69f5a-f6dc-49b3-ac77-fed1a8cecec5.png" alt="image" /></p>

<h2 id="comparison-of-tested-policies">Comparison of tested policies</h2>

<p>The number of collisions displayed on the results are defined as an agent intersection with a neighbour’s collision radius in a given time step. Each agent counts collisions separately, thus two agents colliding is counted as two different collisions and a collisions that lasts for several times steps is is also counted as different collisions.</p>

<p>Percentage of simulations that achieve each number of collisions for each of the three tested policies, n = 5. The percentages for more than 14 collisions (under 1%) have been omitted.</p>

<p><img src="https://user-images.githubusercontent.com/46297629/216673529-5bf6a5be-c149-43cd-b0d7-ead7099d29dd.png" alt="image" /></p>

<p>Effect of the ∆-disk radius (definition 12 on the thesis) on the global reward and number of collisions, averaged over 2000 runs of the trained policies, for the discrete softmax NN policy</p>

<p><img src="https://user-images.githubusercontent.com/46297629/216673581-b48750c7-eedc-4e04-92d4-21ade45c398a.png" alt="image" /></p>

<p>The results also show that the average reward starts to decrease after a certain value of \( \Delta_i \) , in this case around 1. The average number of collisions also increases sharply back to values where the agent has nearly no vision. This unexpected behaviours is the result of significant increase in the complexity of the maximization problem that the policy gradient is trying to solve. Taking into account an increasing number of neighbours and from further distances, increases the variance of the estimated approximated gradient and as a result, the policy used is not able to find improvements. Indeed, for the final case of \( \Delta_i \approx \hat{d}_{i} \) is not able to converge during training.</p>

        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/projects/1-ALPHA-UAV" class="pagination--pager" title="ALPHA, a high altitude UAV
">Previous</a>
    
    
      <a href="http://localhost:4000/projects/3-CANOPIES_KTH" class="pagination--pager" title="LTL for CANOPIES
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/AndreuMatoses"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Andreu Matoses Gimenez. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ZQN5G9F3CC"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-ZQN5G9F3CC', { 'anonymize_ip': false});
</script>






  </body>
</html>

